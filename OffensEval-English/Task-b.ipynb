{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import classification_report, recall_score, make_scorer, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task b: Is the offensive text targeted (TIN) or untargeted (UNT)?\n",
    "– TIN: targeted insult or threat towards a group or an individual;\n",
    "– UNT: text containing untargeted profanity or swearing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2    61866\n",
      "0.3    51800\n",
      "0.5    25999\n",
      "0.4    21966\n",
      "0.6    13090\n",
      "0.7     8072\n",
      "0.8     5056\n",
      "0.1     1106\n",
      "0.9       19\n",
      "Name: average, dtype: int64\n",
      "188974\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "data_b = pd.read_csv('data2/task_b_distant.tsv', sep='\\t', header=0, index_col='id')\n",
    "data_b.head()\n",
    "print(round(data_b[\"average\"],1).value_counts())\n",
    "# # The bigger the more likely it targeted (UNT),\n",
    "#the smaller the more likely it is not targeted (TIN)\n",
    "#At first glance, the data is obviously unbalanced. \n",
    "#If 0.5 is used, there are more TINs less than 0.5.\n",
    "print(len(data_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>average</th>\n",
       "      <th>std</th>\n",
       "      <th>std_min</th>\n",
       "      <th>std_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159533712079503361</th>\n",
       "      <td>@USER Trump is a fucking idiot his dementia is...</td>\n",
       "      <td>0.230133</td>\n",
       "      <td>0.219593</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.449726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533713044234241</th>\n",
       "      <td>@USER HELL YES! His grinned and thumbs up are ...</td>\n",
       "      <td>0.269860</td>\n",
       "      <td>0.178943</td>\n",
       "      <td>0.090918</td>\n",
       "      <td>0.448803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533718345830400</th>\n",
       "      <td>@USER Can't wait to see the shit show his deat...</td>\n",
       "      <td>0.229661</td>\n",
       "      <td>0.228530</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.458192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533739871002625</th>\n",
       "      <td>@USER @USER @USER This guys is dumb check his ...</td>\n",
       "      <td>0.169093</td>\n",
       "      <td>0.180201</td>\n",
       "      <td>-0.011108</td>\n",
       "      <td>0.349293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533742366633984</th>\n",
       "      <td>@USER @USER Fuck him better than his hoes</td>\n",
       "      <td>0.274980</td>\n",
       "      <td>0.276721</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>0.551700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "id                                                                       \n",
       "1159533712079503361  @USER Trump is a fucking idiot his dementia is...   \n",
       "1159533713044234241  @USER HELL YES! His grinned and thumbs up are ...   \n",
       "1159533718345830400  @USER Can't wait to see the shit show his deat...   \n",
       "1159533739871002625  @USER @USER @USER This guys is dumb check his ...   \n",
       "1159533742366633984          @USER @USER Fuck him better than his hoes   \n",
       "\n",
       "                      average       std   std_min   std_max  \n",
       "id                                                           \n",
       "1159533712079503361  0.230133  0.219593  0.010540  0.449726  \n",
       "1159533713044234241  0.269860  0.178943  0.090918  0.448803  \n",
       "1159533718345830400  0.229661  0.228530  0.001131  0.458192  \n",
       "1159533739871002625  0.169093  0.180201 -0.011108  0.349293  \n",
       "1159533742366633984  0.274980  0.276721 -0.001741  0.551700  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#According to the central limit theorem, the edges of the normal distribution are created. \n",
    "#The two parameters can be adjusted. \n",
    "#You can see if the amount of data on both sides after processing is balanced.\n",
    "min_edge = 1\n",
    "max_edge = 1\n",
    "data_b['std_min'] = data_b['average']-(min_edge*data_b['std'])\n",
    "data_b['std_max'] = data_b['average']+(max_edge*data_b['std'])\n",
    "data_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here defines a function to filter data\n",
    "# The larger the more likely it is unt, the smaller the more likely it is tin\n",
    "def select(x,unt_min=0.5 ,tin_max=0.5, std_min=0.5, std_max=0.5,method='std'):\n",
    "    # This method uses only the threshold card mean and does not consider the variance\n",
    "    if method=='average':     \n",
    "        if x[0] >= unt_min:\n",
    "            b_type = 'UNT'\n",
    "        elif x[0] < tin_max:\n",
    "            b_type = 'TIN'\n",
    "        else:\n",
    "            b_type = 'Null'\n",
    "        return b_type\n",
    "\n",
    "    # This method considers the edges of the normal distribution\n",
    "    if method=='std':\n",
    "        if x[1] >= std_min:\n",
    "            b_type = 'UNT'\n",
    "        elif x[2] < std_max:\n",
    "            b_type = 'TIN'\n",
    "        else:\n",
    "            b_type = 'Null'\n",
    "        return b_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "type_list=[]\n",
    "data_b[\"subtask_a\"]='Null'\n",
    "for i in zip(data_b['average'],data_b['std_min'],data_b['std_max']):\n",
    "    type_list.append(select(i)) \n",
    "data_b['subtask_b'] = type_list\n",
    "data_b[\"subtask_b\"].value_counts()\n",
    "data_b[\"subtask_c\"]='Null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159533712079503361</th>\n",
       "      <td>@USER Trump is a fucking idiot his dementia is...</td>\n",
       "      <td>Null</td>\n",
       "      <td>TIN</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533713044234241</th>\n",
       "      <td>@USER HELL YES! His grinned and thumbs up are ...</td>\n",
       "      <td>Null</td>\n",
       "      <td>TIN</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533718345830400</th>\n",
       "      <td>@USER Can't wait to see the shit show his deat...</td>\n",
       "      <td>Null</td>\n",
       "      <td>TIN</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533739871002625</th>\n",
       "      <td>@USER @USER @USER This guys is dumb check his ...</td>\n",
       "      <td>Null</td>\n",
       "      <td>TIN</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159533763791130624</th>\n",
       "      <td>Junhee and I are gonna take turns beating his ...</td>\n",
       "      <td>Null</td>\n",
       "      <td>TIN</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "id                                                                       \n",
       "1159533712079503361  @USER Trump is a fucking idiot his dementia is...   \n",
       "1159533713044234241  @USER HELL YES! His grinned and thumbs up are ...   \n",
       "1159533718345830400  @USER Can't wait to see the shit show his deat...   \n",
       "1159533739871002625  @USER @USER @USER This guys is dumb check his ...   \n",
       "1159533763791130624  Junhee and I are gonna take turns beating his ...   \n",
       "\n",
       "                    subtask_a subtask_b subtask_c  \n",
       "id                                                 \n",
       "1159533712079503361      Null       TIN      Null  \n",
       "1159533713044234241      Null       TIN      Null  \n",
       "1159533718345830400      Null       TIN      Null  \n",
       "1159533739871002625      Null       TIN      Null  \n",
       "1159533763791130624      Null       TIN      Null  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_b = data_b.drop(columns=['average', 'std','std_min','std_max'])\n",
    "data_b = data_b[data_b.subtask_b.isin(['TIN','UNT'])]   # delete null\n",
    "data_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b.to_csv('data/subtask_b_train.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TIN    69506\n",
       "UNT    13216\n",
       "Name: subtask_b, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_b = pd.read_csv('data/subtask_b_train.csv', sep='\\t', header=0, index_col='id')\n",
    "data_b[\"subtask_b\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13240\n",
      "4400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TIN    3876\n",
       "UNT     524\n",
       "Name: subtask_b, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/olid-training-v1.0.tsv', sep='\\t', header=0, index_col='id')\n",
    "print(len(test))\n",
    "test = test[test.subtask_b.isin(['TIN','UNT'])] \n",
    "print(len(test))\n",
    "test[\"subtask_b\"].value_counts()\n",
    "test.to_csv('data/subtask_b_test.csv',sep='\\t')\n",
    "test[\"subtask_b\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing is complete, ready for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_taskb(task_sign,C=1,g='scale',k='rbf'):\n",
    "\n",
    "    train_samples = read_file('data/subtask_b_train',task_sign)\n",
    "    X, y = [ x[\"text\"] for x in train_samples ], [ x[\"label\"] for x in train_samples ]\n",
    "    #print(y)\n",
    "    bow = CountVectorizer(max_features=3000)\n",
    "    tfidf = TfidfTransformer()\n",
    "\n",
    "    svm_clf = SVC(C, gamma=g, kernel=k)\n",
    "\n",
    "    pipeline = Pipeline([('bow', bow),\n",
    "                        ('tfidf', tfidf),\n",
    "                        ('clf', svm_clf),])\n",
    "\n",
    "    print('\\tTraining on', len(X), 'samples')\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    predictions = pipeline.predict(X)\n",
    "    print ('-'* 40, '\\nTraining data\\n', classification_report(y, predictions, digits=3))\n",
    "\n",
    "    # Testing\n",
    "    print(\"Evaluating SVM classifier\")\n",
    "    test_samples = read_file('data/subtask_b_test',task_sign)\n",
    "    X, y = [ x[\"text\"] for x in test_samples ], [ x[\"label\"] for x in test_samples ]\n",
    "\n",
    "    predictions = pipeline.predict(X)\n",
    "    print ('Test data\\n', classification_report(y, predictions, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data: 82722\n",
      "\tTraining on 82722 samples\n",
      "---------------------------------------- \n",
      "Training data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000     69506\n",
      "           1      0.999     0.999     0.999     13216\n",
      "\n",
      "    accuracy                          1.000     82722\n",
      "   macro avg      0.999     0.999     0.999     82722\n",
      "weighted avg      1.000     1.000     1.000     82722\n",
      "\n",
      "Evaluating SVM classifier\n",
      "Total number of data: 4400\n",
      "Test data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.908     0.968     0.937      3876\n",
      "           1      0.543     0.279     0.368       524\n",
      "\n",
      "    accuracy                          0.886      4400\n",
      "   macro avg      0.726     0.623     0.653      4400\n",
      "weighted avg      0.865     0.886     0.870      4400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_taskb('B')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
